{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13877fc9-720b-4c4d-bbdb-34fe5c168e45",
   "metadata": {},
   "source": [
    "# Lab Seven: RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cafae8-8644-4ecb-98dd-75cc82f5f374",
   "metadata": {},
   "source": [
    "### Maria Harrison, Garrett Webb, Jackson Heck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf5a75-a79e-4d52-9f59-b6b5d206aca3",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46defd9e-c005-40a4-9128-b2a8d2ad4d88",
   "metadata": {},
   "source": [
    "[2 points] Define and prepare your data set. Provide details about the source of the data. Discuss methods of tokenization in your dataset as well as any decisions to force a specific length of sequence.  Also discuss your rationale for the size and nature of your vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904a8a9-a7ea-47f2-96aa-5b36f06686ef",
   "metadata": {},
   "source": [
    "We chose a small subset of a dataset of book reviews from the Amazon Kindle Store. The dataset contains 12,000 samples. Each sample contains a rating and the review text of the product. We will be performing sentiment analysis (many-to-one).\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83a06381-5b2a-4ecf-a91e-4dd0b5ae745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>This book was the very first bookmobile book I...</td>\n",
       "      <td>50 + years ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>When I read the description for this book, I c...</td>\n",
       "      <td>Boring! Boring! Boring!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>I just had to edit this review. This book is a...</td>\n",
       "      <td>Wiggleliscious/new toy ready/!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>I don't normally buy 'mystery' novels because ...</td>\n",
       "      <td>Very good read.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>This isn't the kind of book I normally read, a...</td>\n",
       "      <td>Great Story!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rating                                         reviewText  \\\n",
       "0           0       5  This book was the very first bookmobile book I...   \n",
       "1           1       1  When I read the description for this book, I c...   \n",
       "2           2       5  I just had to edit this review. This book is a...   \n",
       "3           3       5  I don't normally buy 'mystery' novels because ...   \n",
       "4           4       5  This isn't the kind of book I normally read, a...   \n",
       "\n",
       "                           summary  \n",
       "0                50 + years ago...  \n",
       "1          Boring! Boring! Boring!  \n",
       "2  Wiggleliscious/new toy ready/!!  \n",
       "3                  Very good read.  \n",
       "4                     Great Story!  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('/Users/marycateharrison/Library/Mobile Documents/com~apple~CloudDocs/SMU/spring-2023/machine-learning/preprocessed_kindle_review .csv')\n",
    "# view sample of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c8f59b3-6beb-400c-b3ca-c6f5be34beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>This book was the very first bookmobile book I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When I read the description for this book, I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I just had to edit this review. This book is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>I don't normally buy 'mystery' novels because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This isn't the kind of book I normally read, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                         reviewText\n",
       "0       5  This book was the very first bookmobile book I...\n",
       "1       1  When I read the description for this book, I c...\n",
       "2       5  I just had to edit this review. This book is a...\n",
       "3       5  I don't normally buy 'mystery' novels because ...\n",
       "4       5  This isn't the kind of book I normally read, a..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'summary'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3eebd28c-0afa-4177-a20f-50f42107ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = 1, neg = 0\n",
    "df['rating'] = df['rating'].replace(to_replace=[1, 2, 3, 4, 5],value=[0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97d8efc1-e792-41d3-8516-c77f159bc11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(df['rating'].value_counts()[0])\n",
    "print(df['rating'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72753c6a-3cb3-4cec-9bc7-dbd4175f57ab",
   "metadata": {},
   "source": [
    "Next, I wanted to visualize the general word count of all the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b52e9d07-3302-4b40-94b9-c4769e47a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5020 2908 3834 226 11\n"
     ]
    }
   ],
   "source": [
    "text_numpy = df.reviewText.to_numpy()\n",
    "\n",
    "num_less_than_50 = 0\n",
    "num_less_than_100 = 0\n",
    "num_less_than_500 = 0\n",
    "num_less_than_1k = 0\n",
    "num_less_than_2k = 0\n",
    "\n",
    "for i in text_numpy:\n",
    "    if(len(i.split()) < 50):\n",
    "        num_less_than_50 +=1\n",
    "    elif(len(i.split()) < 100):\n",
    "        num_less_than_100 +=1\n",
    "    elif(len(i.split()) < 500):\n",
    "        num_less_than_500 +=1\n",
    "    elif(len(i.split()) < 1000):\n",
    "        num_less_than_1k += 1\n",
    "    elif(len(i.split()) < 2000):\n",
    "        num_less_than_2k += 1\n",
    "        \n",
    "print(num_less_than_50, num_less_than_100, num_less_than_500, num_less_than_1k, num_less_than_2k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909b9a8-9421-4e9f-9fd7-659a8c8e3b94",
   "metadata": {},
   "source": [
    "It appears that most of the reviews are in the range of 0 to 500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d7273b-5836-4cb5-ad1d-d36fa93049f4",
   "metadata": {},
   "source": [
    "Discuss methods of tokenization in your dataset as well as any decisions to force a specific length of sequence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bdbaecb-8e13-4f7b-a26f-58e08e93b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33056 unique tokens. Distilled to 33056 top words.\n",
      "Shape of data tensor: (12000, 500)\n",
      "Shape of label tensor: (12000, 2)\n",
      "33056\n",
      "CPU times: user 1.35 s, sys: 31.1 ms, total: 1.38 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = df.reviewText.to_numpy()\n",
    "y = df['rating'].to_numpy()\n",
    "\n",
    "NUM_TOP_WORDS = None\n",
    "MAX_ART_LEN = 500 # max and min num of words\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(y, NUM_CLASSES)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y_ohe.shape)\n",
    "print(np.max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38265a34-f918-4414-bcff-bfedbb26db9a",
   "metadata": {},
   "source": [
    "[0.5 points] Choose and explain what metric(s) you will use to evaluate your algorithm’s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c017c01-abcb-47d8-8c74-0a7ffe415a8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78581eee-079c-4aff-8ff0-e6b6a7932897",
   "metadata": {},
   "source": [
    "[0.5 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your train/test splitting method is a realistic mirroring of how an algorithm would be used in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbeb8109-7a45-4450-80aa-1c7b70436b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (9600, 500) Label Shape: (9600, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X, y_ohe, test_size=0.2,\n",
    "                                                            stratify=y)\n",
    "\n",
    "# print some stats of the data\n",
    "print(\"X_train Shape:\",X_train.shape, \"Label Shape:\", y_train_ohe.shape)\n",
    "uniq_classes = np.sum(y_train_ohe,axis=0)\n",
    "plt.bar(list(range(2)),uniq_classes)\n",
    "plt.xticks(list(range(2)), class_labels, rotation='vertical')\n",
    "plt.ylabel(\"Number of Instances in Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193c29e-72dc-4daf-980d-430451d105ed",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a44fb9-b5cf-49ae-8470-e88bbb532721",
   "metadata": {},
   "source": [
    "[2 points] Investigate at least two different recurrent network architectures  Be sure to use an embedding layer . Adjust hyper-parameters of the networks as needed to improve generalization performance (train a total of at least four models). Discuss the performance of each network and compare them. Justify your choice of parameters for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0b80eed-935c-4ca3-981b-35ac6721ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Embedding Shape: (33057, 200) \n",
      " Total words found: 26163 \n",
      " Percentage: 79.14511298665941\n",
      "CPU times: user 12.1 s, sys: 479 ms, total: 12.6 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 200\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('/Users/marycateharrison/Library/Mobile Documents/com~apple~CloudDocs/SMU/spring-2023/machine-learning/glove.6B/glove.6B.200d.txt')\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "      \"Total words found:\",found_words, \"\\n\",\n",
    "      \"Percentage:\",100*found_words/embedding_matrix.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ab77686-127a-45c2-a237-ce187d8d4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# save this embedding now\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38a66e24-ec75-494c-bd0b-df9b41c15b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b3cb2d9-2835-44b0-8300-8422fb3037cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(embedding_layer)\n",
    "lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=.2))\n",
    "lstm.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "lstm.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gru = Sequential()\n",
    "gru.add(embedding_layer)\n",
    "gru.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "gru.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "gru.compile(loss='binary_crossentropy', \n",
    "              optimizer= 'rmsprop', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26c9eb-bda3-46b5-b350-04e9c8b85145",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm = []\n",
    "tmp = lstm.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=6, batch_size=64)\n",
    "history_lstm.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762b4d2-801e-4535-82f9-0f0a0e719854",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gru = []\n",
    "tmp = gru.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=6, batch_size=64)\n",
    "history_gru.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9027ce6-2926-4465-a3df-e4fc0f3d6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_2 = Sequential()\n",
    "lstm_2.add(embedding_layer)\n",
    "lstm_2.add(LSTM(100, dropout=0.2, recurrent_dropout=.2))\n",
    "lstm_2.add(Dense(NUM_CLASSES, activation='relu'))\n",
    "lstm_2.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gru_2 = Sequential()\n",
    "gru_2.add(embedding_layer)\n",
    "gru_2.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "gru_2.add(Dense(NUM_CLASSES, activation='relu'))\n",
    "gru_2.compile(loss='binary_crossentropy', \n",
    "              optimizer= 'adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131e50d-d412-4eb3-a5ba-3ed7a16c3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm_2 = []\n",
    "tmp = lstm_2.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=6, batch_size=64)\n",
    "history_lstm_2.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b467689-7914-490a-856e-8a685e5d485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gru_2 = []\n",
    "tmp = gru_2.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=6, batch_size=64)\n",
    "history_gru_2.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe76bbc-7325-47a7-9cd1-14655c515818",
   "metadata": {},
   "source": [
    "[1 points] Using the best parameters and architecture from the RNN in the previous step, add a second recurrent chain to your RNN. The input to the second chain should be the output sequence of the first chain. Visualize the performance of training and validation sets versus the training iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fdc5b4-3bcb-41c6-a0a8-225e865484ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extend the training by a number of epochs\n",
    "tmp = rnn.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=6, batch_size=64)\n",
    "history.append( tmp )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f60b82-dc73-4253-abda-93f940437333",
   "metadata": {},
   "source": [
    "[0.5 points] Use the method of train/test splitting and evaluation criteria that you argued for at the beginning of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d636f93-979f-4c4b-89e5-6674f383f89c",
   "metadata": {},
   "source": [
    "[0.5 points] Run to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df107f6d-e737-4db8-943b-672209cb5053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a5cd8-d994-4803-baa1-aec8055211ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066812c-f676-4781-962e-8f698f627939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the history from training together\n",
    "combined = dict()\n",
    "for key in ['accuracy','val_accuracy','loss','val_loss']:\n",
    "    combined[key] = np.hstack([x.history[key] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562a43-cfab-47c7-abf9-2f34d5e5b045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c23601d-b3a6-422e-b50a-d2948bb1055b",
   "metadata": {},
   "source": [
    "[1 point]  Visualize the results of all the RNNs you trained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdbdb3-dff7-4e02-b4d5-496055247d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1f8645-9f14-416c-b001-de9a42b45aeb",
   "metadata": {},
   "source": [
    "## 3. Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e15783-116b-4b5a-992e-994cc1c555d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
